# ğŸ§  Athena Conversational AI Copilot

![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)
![Next.js](https://img.shields.io/badge/Next.js-000000?style=for-the-badge&logo=nextdotjs)
![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?style=for-the-badge&logo=typescript)
![TailwindCSS](https://img.shields.io/badge/TailwindCSS-38B2AC?style=for-the-badge&logo=tailwindcss)
![MongoDB](https://img.shields.io/badge/MongoDB-4EA94B?style=for-the-badge&logo=mongodb)
![Pinecone](https://img.shields.io/badge/Pinecone-3B82F6?style=for-the-badge&logo=pinecone)
![Groq](https://img.shields.io/badge/Groq-412991?style=for-the-badge&logo=groq)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker)
![Vercel](https://img.shields.io/badge/Vercel-000000?style=for-the-badge&logo=vercel)

---

A **multimodal conversational AI system** that integrates text and image understanding using a **Retrieval-Augmented Generation (RAG)** pipeline with **Pinecone**, **MongoDB**, and **GROQ APIs** â€” built with a **FastAPI** backend and a **Next.js** frontend.

---

## ğŸš€ Overview

Athena Conversational AI Copilot is designed to act as an intelligent assistant capable of handling **contextual text queries**, **image-based understanding**, and **knowledge retrieval** from custom data sources.

The project combines **FastAPI**, **Pinecone**, **GROQ**, and **MongoDB** for backend intelligence, while the **Next.js + TypeScript** frontend delivers a sleek chat interface for human-AI interaction.

The system leverages:

- **FastAPI** for backend orchestration
- **Pinecone** for semantic vector retrieval
- **GROQ** for natural language reasoning and multimodal generation
- **Next.js** for a clean, reactive, and responsive chat interface

---

## âš™ï¸ Tech Stack

### ğŸ§© Backend (FastAPI)

- **Python** (FastAPI, Uvicorn)
- **GROQ API** for text and multimodal responses
- **Pinecone Vector Database** for retrieval and context search
- **MongoDB** for storing conversations and chat metadata
- **Docker** for containerized deployment

### ğŸ’» Frontend (Next.js + TypeScript)

- **Next.js 14 (App Router)** with **TypeScript**
- **Tailwind CSS** for styling
- **Clerk** for authentication and user management
- **React Context API** for chat state management
- **Deployed on Vercel**

---

## ğŸ—‚ï¸ Directory Structure

```bash
ankit5803-athena-conversational-ai-copilot/
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app.py
â”‚ â”œâ”€â”€ blip.py
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â”œâ”€â”€ manual_ingestion.py
â”‚ â”œâ”€â”€ mongodb.py
â”‚ â”œâ”€â”€ multimodal.py
â”‚ â”œâ”€â”€ pinecone_ingestion.py
â”‚ â”œâ”€â”€ preprocess_pipeline.py
â”‚ â”œâ”€â”€ rag_pipeline.py
â”‚ â””â”€â”€ requirements.txt
â””â”€â”€ frontend/
â”œâ”€â”€ next.config.ts
â”œâ”€â”€ package.json
â”œâ”€â”€ postcss.config.mjs
â”œâ”€â”€ tailwind.config.ts
â”œâ”€â”€ tsconfig.json
â””â”€â”€ src/
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ layout.tsx
â”‚ â”œâ”€â”€ page.tsx
â”‚ â”œâ”€â”€ api/
â”‚ â”‚ â”œâ”€â”€ chat/
â”‚ â”‚ â”‚ â”œâ”€â”€ route.ts
â”‚ â”‚ â”‚ â””â”€â”€ [id]/
â”‚ â”‚ â”‚ â”œâ”€â”€ route.ts
â”‚ â”‚ â”‚ â”œâ”€â”€ messages/
â”‚ â”‚ â”‚ â”‚ â””â”€â”€ route.ts
â”‚ â”‚ â”‚ â””â”€â”€ streammsg/
â”‚ â”‚ â”‚ â””â”€â”€ route.ts
â”‚ â”‚ â”œâ”€â”€ folder/
â”‚ â”‚ â”‚ â”œâ”€â”€ route.ts
â”‚ â”‚ â”‚ â””â”€â”€ [id]/route.ts
â”‚ â”‚ â””â”€â”€ user/route.ts
â”‚ â””â”€â”€ chat/page.tsx
â”œâ”€â”€ components/
â”‚ â”œâ”€â”€ AIAssistantUI.tsx
â”‚ â”œâ”€â”€ ChatPane.tsx
â”‚ â”œâ”€â”€ Composer.tsx
â”‚ â”œâ”€â”€ Sidebar.tsx
â”‚ â”œâ”€â”€ Message.tsx
â”‚ â””â”€â”€ contexts/ChatContext.tsx
â”œâ”€â”€ interfaces/
â”‚ â””â”€â”€ interface.ts
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ Conversation.ts
â”‚ â”œâ”€â”€ Folder.ts
â”‚ â”œâ”€â”€ Message.ts
â”‚ â””â”€â”€ User.ts
â””â”€â”€ utils/
â”œâ”€â”€ database.ts
â””â”€â”€ util.ts
```

---

## ğŸ”‘ Environment Variables

### Backend (`.env`)

```bash
GROQ_API_KEY=your_groq_api_key
PINECONE_API_KEY=your_pinecone_api_key
MONGO_URI=your_mongodb_connection_string
```

### Frontend(`.env`)

```bash
BACKEND_URL=http://localhost:8000
MONGO_URI=your_mongodb_connection_string
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=your_clerk_publishable_key
CLERK_SECRET_KEY=your_clerk_secret_key
```

---

## ğŸ§  Core Features

- **RAG (Retrieval-Augmented Generation)** pipeline using Pinecone for context retrieval

- **Multimodal understanding** â€” supports both text and image inputs

- **Conversational memory** stored in MongoDB

- **Dynamic chat folder and message** management

- **Clerk authentication** for secure user sessions

- **Real-time streaming responses** from backend to frontend using Server-Sent Events (SSE)

- **Dockerized backend** for easy deployment

- **Modern Next.js UI** with responsive, animated chat experience

---

## âš¡ Setup Instructions

### ğŸ³ Backend (FastAPI)

1. Clone the repository

```bash
git clone https://github.com/ankit5803/athena-conversational-ai-copilot.git
cd athena-conversational-ai-copilot/backend
```

2. Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate  # for Mac/Linux
venv\Scripts\activate     # for Windows
```

4. Install dependencies

```bash
pip install -r requirements.txt
```

5. Run the FastAPI server

```bash
uvicorn app:app --host 0.0.0.0 --port 8000 --reload
```

6. Docker (optional)

```bash
docker build -t athena-backend .
docker run -d -p 8000:8000 athena-backend
```

### ğŸ’» Frontend (Next.js)

1. Navigate to frontend folder

```bash
cd ../frontend
```

2. Install dependencies

```bash
npm install
```

3. Run development server

```bash
npm run dev
```

App will be available at:
ğŸ‘‰ `http://localhost:3000`

---

## ğŸ”— API Endpoints (Backend)

| Endpoint  | Method | Description                             |
| --------- | ------ | --------------------------------------- |
| `/search` | POST   | Perform RAG-based query (SSE streaming) |
| `/health` | GET    | Check backend health                    |

---

## ğŸ“¦ Deployment

- **Backend** â†’ Deployed via Docker on Render(any cloud/VPS or container service)

- **Frontend** â†’ Deployed on Vercel

- Both parts communicate via the environment variable `BACKEND_URL`

---

## ğŸ§­ Folder Highlights

### ğŸ§  Backend Logic

- **rag_pipeline.py** â†’ Handles context retrieval from Pinecone

- **multimodal.py** â†’ Integrates BLIP image understanding

- **mongodb.py** â†’ Handles MongoDB interactions

- **preprocess_pipeline.py** â†’ Cleans and prepares documents before embedding

- **manual_ingestion.py / pinecone_ingestion.py** â†’ Handle knowledge ingestion

### ğŸ’¬ Frontend Components

- **AIAssistantUI.tsx** â†’ Core chat interface

- **ChatPane.tsx** â†’ Displays conversation stream

- **Composer.tsx** â†’ Input area with actions

- **Sidebar.tsx** â†’ Folder & conversation navigation

- **ChatContext.tsx** â†’ Manages global chat state

---

## ğŸ§‘â€ğŸ’» Contributions

- **[Sandarva-9304](https://github.com/Sandarva-9304)**

- **[ankit-5803](https://github.com/ankit-5803)**

Feel free to fork the repository, open issues, or submit pull requests to improve the project!

---
